{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bfc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a247dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# STATELESS HELPER CLASSES - IMPLEMENT THE CORE FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "class Calib:\n",
    "    @staticmethod\n",
    "    def load_K(json_data):\n",
    "        data = json.loads(json_data) if isinstance(json_data, str) else json_data\n",
    "        return np.array(data.get('K', np.eye(3)), dtype=np.float32), np.array(data.get('distCoeffs', [0]*5), dtype=np.float32)\n",
    "\n",
    "class Model:\n",
    "    @staticmethod\n",
    "    def load_points(data):\n",
    "        points = json.loads(data) if isinstance(data, str) else data\n",
    "        points = np.array(points, dtype=np.float32)\n",
    "        return points if points.shape[1] == 3 else np.column_stack([points, np.zeros(len(points))])\n",
    "\n",
    "class Clicks:\n",
    "    @staticmethod\n",
    "    def capture(points_list):\n",
    "        return np.array(points_list, dtype=np.float32) if points_list else np.array([]).reshape(0, 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_numbered(image, points, radius=8):\n",
    "        if isinstance(image, np.ndarray): image = Image.fromarray(image)\n",
    "        img = image.copy()\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        try: font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "        except: font = ImageFont.load_default()\n",
    "        for i, (x, y) in enumerate(points):\n",
    "            draw.ellipse([x-radius, y-radius, x+radius, y+radius], outline=(255, 0, 0), width=2, fill=(255, 255, 255))\n",
    "            draw.text((x-5, y-8), str(i+1), fill=(0, 0, 0), font=font)\n",
    "        return img\n",
    "\n",
    "class Pose:\n",
    "    @staticmethod\n",
    "    def from_homography(K, model_2D, image_2D):\n",
    "        \"\"\"IMPLEMENT: Homography->Pose decomposition\"\"\"\n",
    "        return np.eye(3, dtype=np.float32), np.zeros((3, 1), dtype=np.float32)  # Placeholder\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_opencv(K, distCoeffs, model_3D, image_2D):\n",
    "        \"\"\"IMPLEMENT: OpenCV solvePnP\"\"\"\n",
    "        return np.eye(3, dtype=np.float32), np.zeros((3, 1), dtype=np.float32)  # Placeholder\n",
    "\n",
    "class Viz:\n",
    "    \n",
    "    @staticmethod\n",
    "    def overlay_reprojection(image, model_3D, image_2D, K, distCoeffs, R, t):\n",
    "        \"\"\"IMPLEMENT: Show reprojection overlay\"\"\"\n",
    "        if isinstance(image, np.ndarray): image = Image.fromarray(image)\n",
    "        img = image.copy()\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for x, y in image_2D:\n",
    "            draw.ellipse([x-5, y-5, x+5, y+5], outline=(255, 0, 0), width=2)\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_camera_3d(R, t):\n",
    "        \"\"\"IMPLEMENT: 3D camera pose visualization\"\"\"\n",
    "        fig = plt.figure(figsize=(6, 5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter([0], [0], [0], color='black', s=100, label='World Origin')\n",
    "        cam_pos = -R.T @ t\n",
    "        ax.scatter(cam_pos[0], cam_pos[1], cam_pos[2], color='red', s=100, label='Camera')\n",
    "        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z'); ax.set_title('Camera Pose'); ax.legend()\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        plt.close(fig)\n",
    "        return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d89de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SINGLE-CELL GRADIO DEMO\n",
    "# ============================================================================\n",
    "\n",
    "def create_pose_estimation_demo():\n",
    "    state = {'points': [], 'model_3d': None, 'K': None, 'dist': None, 'image': None}\n",
    "    \n",
    "    def on_click(evt: gr.SelectData, img):\n",
    "        if img is None: return img, \"\"\n",
    "        x, y = evt.index\n",
    "        state['points'].append([int(x), int(y)])\n",
    "        state['image'] = img\n",
    "        points_text = \"\\n\".join([f\"Point {i+1}: ({x}, {y})\" for i, (x, y) in enumerate(state['points'])])\n",
    "        return np.array(Clicks.draw_numbered(img, state['points'])), points_text\n",
    "    \n",
    "    def undo_last(img):\n",
    "        if state['points']: state['points'].pop()\n",
    "        points_text = \"\\n\".join([f\"Point {i+1}: ({x}, {y})\" for i, (x, y) in enumerate(state['points'])])\n",
    "        return np.array(Clicks.draw_numbered(img, state['points'])) if img is not None and state['points'] else img, points_text\n",
    "\n",
    "    \n",
    "    def clear_points(img):\n",
    "        state['points'].clear()\n",
    "        return img, \"\"\n",
    "    \n",
    "    def load_intrinsics_auto():\n",
    "        if os.path.exists(\"calibration.json\"):\n",
    "            try:\n",
    "                with open(\"calibration.json\", 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                state['K'], state['dist'] = Calib.load_K(data)\n",
    "                return f\"Loaded from calibration.json: K shape {state['K'].shape}, dist shape {state['dist'].shape}\"\n",
    "            except Exception as e:\n",
    "                return f\"Error loading calibration.json: {e}\"\n",
    "        return \"No calibration.json found - enter manually\"\n",
    "\n",
    "    def load_intrinsics_text(text):\n",
    "        if not text.strip(): return \"No text entered\"\n",
    "        try:\n",
    "            state['K'], state['dist'] = Calib.load_K(text)\n",
    "            return f\"Loaded from text: K shape {state['K'].shape}, dist shape {state['dist'].shape}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error parsing text: {e}\"\n",
    "    \n",
    "    def load_model_points(text):\n",
    "        try:\n",
    "            state['model_3d'] = Model.load_points(text)\n",
    "            return f\"Loaded {len(state['model_3d'])} points\"\n",
    "        except:\n",
    "            return \"Error loading points\"\n",
    "    \n",
    "    def estimate_poses(intrinsics_text):\n",
    "        if not state['points'] or not intrinsics_text: return \"Missing data\"\n",
    "        try:\n",
    "            state['K'], state['dist'] = Calib.load_K(intrinsics_text)\n",
    "            image_pts = Clicks.capture(state['points'])\n",
    "            \n",
    "            if state['model_3d'] is None or len(image_pts) != len(state['model_3d']):\n",
    "                return \"Point count mismatch\"\n",
    "            \n",
    "            # Homography method (2D)\n",
    "            R_h, t_h = Pose.from_homography(state['K'], state['model_3d'][:, :2], image_pts)\n",
    "            \n",
    "            # OpenCV method (3D)\n",
    "            R_cv, t_cv = Pose.from_opencv(state['K'], state['dist'], state['model_3d'], image_pts)\n",
    "            \n",
    "            return f\"Homography R,t:\\n{R_h}\\n{t_h.flatten()}\\n\\nOpenCV R,t:\\n{R_cv}\\n{t_cv.flatten()}\"\n",
    "        except Exception as e:\n",
    "            return f\"Estimation failed: {e}\"\n",
    "    \n",
    "    def create_overlay():\n",
    "        if not all([state['image'], state['points'], state['model_3d'], state['K']]):\n",
    "            return state['image']\n",
    "        try:\n",
    "            image_pts = Clicks.capture(state['points'])\n",
    "            R, t = Pose.from_opencv(state['K'], state['dist'], state['model_3d'], image_pts)\n",
    "            overlay = Viz.overlay_reprojection(state['image'], state['model_3d'], image_pts, state['K'], state['dist'], R, t)\n",
    "            return np.array(overlay)\n",
    "        except:\n",
    "            return state['image']\n",
    "    \n",
    "    def create_3d_plot():\n",
    "        if not all([state['points'], state['model_3d'], state['K']]):\n",
    "            return None\n",
    "        try:\n",
    "            image_pts = Clicks.capture(state['points'])\n",
    "            R, t = Pose.from_opencv(state['K'], state['dist'], state['model_3d'], image_pts)\n",
    "            return Viz.plot_camera_3d(R, t)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    with gr.Blocks(title=\"Pose Estimation\") as demo:\n",
    "        gr.Markdown(\"# Pose Estimation Interface\")\n",
    "        gr.Markdown(\"Upload image, set intrinsics, define model points, click features, estimate pose\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                img = gr.Image(label=\"Image\", type=\"numpy\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    undo_btn = gr.Button(\"Undo\")\n",
    "                    clear_btn = gr.Button(\"Clear\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                intrinsics_txt = gr.Textbox(label=\"Camera Intrinsics\", lines=3,\n",
    "                    placeholder='{\"K\": [[800,0,320],[0,800,240],[0,0,1]], \"distCoeffs\": [0,0,0,0,0]}')\n",
    "                intrinsics_status = gr.Textbox(label=\"Intrinsics Status\")\n",
    "                \n",
    "                model_points_txt = gr.Textbox(label=\"Model Points\", lines=3,\n",
    "                    placeholder='[[0,0,0],[1,0,0],[1,1,0],[0,1,0]]')\n",
    "                model_status = gr.Textbox(label=\"Model Points Status\")\n",
    "                \n",
    "                points_coordinates = gr.Textbox(label=\"Clicked Points\", lines=4, interactive=False)\n",
    "        \n",
    "        with gr.Row():\n",
    "            estimate_btn = gr.Button(\"Estimate Pose\", variant=\"primary\")\n",
    "            overlay_btn = gr.Button(\"Show Overlay\")\n",
    "        \n",
    "        with gr.Tabs():\n",
    "            with gr.Tab(\"Pose Results\"):\n",
    "                results_txt = gr.Textbox(label=\"Results\", lines=8, interactive=False)\n",
    "            \n",
    "            with gr.Tab(\"3D Visualization\"):\n",
    "                plot_3d = gr.Image(label=\"Camera Pose\")\n",
    "            \n",
    "            with gr.Tab(\"Overlay\"):\n",
    "                overlay_img = gr.Image(label=\"Reprojection Overlay\")\n",
    "        \n",
    "        # Event handlers\n",
    "        img.select(on_click, inputs=[img], outputs=[img, points_coordinates])\n",
    "        undo_btn.click(undo_last, inputs=[img], outputs=[img, points_coordinates])\n",
    "        clear_btn.click(clear_points, inputs=[img], outputs=[img, points_coordinates])\n",
    "        intrinsics_txt.change(load_intrinsics_text, inputs=[intrinsics_txt], outputs=[intrinsics_status])\n",
    "        model_points_txt.change(load_model_points, inputs=[model_points_txt], outputs=[model_status])\n",
    "        estimate_btn.click(estimate_poses, inputs=[intrinsics_txt], outputs=[results_txt])\n",
    "        overlay_btn.click(create_overlay, outputs=[overlay_img])\n",
    "        plot_3d.change(lambda: create_3d_plot(), outputs=[plot_3d])\n",
    "\n",
    "        demo.load(load_intrinsics_auto, outputs=[intrinsics_status])\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84143499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://785b7ae09615045f41.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://785b7ae09615045f41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the demo\n",
    "demo = create_pose_estimation_demo()\n",
    "demo.launch(debug=False, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
