{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8622af0-3013-4719-af43-3278e00db728",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/a3d2ddk/Prenith-and-Drew-Estimate-Camera-Poses.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ffe8c751-91b0-4821-af52-bafe64cb10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pytransform3d.camera as pc\n",
    "import pytransform3d.transformations as pt\n",
    "import matplotlib.pyplot as plt\n",
    "import threading, json, os, io\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b4a8804c-e34a-4e51-81ab-50e304f48817",
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def get_homography(X, W):\n",
    "    u = W[0,:]\n",
    "    v = W[1,:]\n",
    "\n",
    "    x = X[0,:]\n",
    "    y = X[1,:]\n",
    "\n",
    "    I = 4\n",
    "    \n",
    "    A = np.zeros((2*I, 9))\n",
    "    j = 0\n",
    "    for i in range(0,I):\n",
    "        A[j,:]  = [0, 0, 0, -u[i], -v[i], -1, y[i]*u[i], y[i]*v[i], y[i]]\n",
    "        A[j+1,:]  = [u[i], v[i], 1, 0, 0, 0, -x[i]*u[i], -x[i]*v[i], -x[i]]\n",
    "        j = j + 2\n",
    "\n",
    "    U, D, V = np.linalg.svd(A)\n",
    "\n",
    "    phi_h = V.T[:,-1]\n",
    "\n",
    "    phi_hr = scipy.optimize.minimize(obj_funct,x0=phi_h, args=(x, y, u, v))\n",
    "\n",
    "    phi = np.reshape(phi_hr.x, (3,3))\n",
    "    \n",
    "    return phi\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def obj_funct(phi, x, y, u, v):\n",
    "    I = x.shape[0]\n",
    "    sum_squares = 0.0\n",
    "\n",
    "    for i in range(0, I):\n",
    "        d = phi[6] * u[i] + phi[7] * v[i] + phi[8]\n",
    "        if d == 0:  # Avoid division by zero\n",
    "            continue\n",
    "\n",
    "        n1 = phi[0] * u[i] + phi[1] * v[i] + phi[2]\n",
    "        x_model = n1 / d\n",
    "\n",
    "        n2 = phi[3] * u[i] + phi[4] * v[i] + phi[5]\n",
    "        y_model = n2 / d\n",
    "\n",
    "        squared_norm = (x[i] - x_model) ** 2 + (y[i] - y_model) ** 2\n",
    "        sum_squares += squared_norm\n",
    "\n",
    "    return sum_squares\n",
    "\n",
    "@staticmethod\n",
    "def get_pose_hom(lam, dist, X, W):\n",
    "    X = X.reshape(-1, 1, 2)\n",
    "    X = cv.undistortPoints(X, lam, dist)\n",
    "    X = X.reshape(-1, 2).T\n",
    "\n",
    "    hom = get_homography(X, W)\n",
    "    lam_inv = np.linalg.inv(lam)\n",
    "    hom_ext = np.dot(lam_inv, hom)\n",
    "\n",
    "    # Use the full hom_ext for SVD\n",
    "    U, L, V = np.linalg.svd(hom_ext)\n",
    "    rotation = U @ V  # This will give you a 3x3 rotation matrix\n",
    "\n",
    "    # Validate rotation matrix\n",
    "    if np.linalg.det(rotation) < 0:\n",
    "        rotation[:, 2] *= -1\n",
    "\n",
    "    # Calculate scale and translation\n",
    "    scale = np.sum(hom_ext[:, 0:2] / rotation[:, 0:2]) / 6\n",
    "    translation = hom_ext[:, 2] / scale\n",
    "\n",
    "    return rotation, translation\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def get_pose_cv(lam, dist, X, W):\n",
    "    X = X.reshape(-1, 2)\n",
    "    W = W.reshape(-1, 3)\n",
    "\n",
    "    _, rvec, translation = cv.solvePnP(W, X, lam, dist)\n",
    "\n",
    "    rotation, _ = cv.Rodrigues(rvec)\n",
    "    \n",
    "    return rotation, translation\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def img_with_axis(img, lam, rot, tvec, dist):\n",
    "    rvec, _ = cv.Rodrigues(rot)\n",
    "            \n",
    "    W = 2 * np.array([\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    image_axes, jac = cv.projectPoints(W, rvec, tvec, lam, dist)\n",
    "\n",
    "    #print(image_axes)\n",
    "\n",
    "    image_axes = image_axes.squeeze().T\n",
    "\n",
    "    x0, y0 = image_axes[:,0].astype(int)\n",
    "    cv.circle(img, (x0, y0), 9, (0, 0, 0), -1)\n",
    "\n",
    "    x1, y1 = image_axes[:,1].astype(int)\n",
    "    img = cv.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 5)\n",
    "\n",
    "    x2, y2 = image_axes[:,2].astype(int)\n",
    "    img = cv.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "    x3, y3 = image_axes[:,3].astype(int)\n",
    "    img = cv.arrowedLine(img, (x0, y0), (x0 + (x0 - x3), y0 + (y0 - y3)), (0, 0, 255), 5)\n",
    "\n",
    "    pil = Image.fromarray(img)\n",
    "\n",
    "    return pil\n",
    "\n",
    "@staticmethod\n",
    "def get_camera_pose_plot(lam, img, rot, tvec):\n",
    "    \"\"\"Get camera pose visualization\"\"\"\n",
    "    \n",
    "    # Prepare the figure for plotting\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    nRows, nCols, _ = img.shape\n",
    "\n",
    "    sensor_size = np.array([nCols, nRows])\n",
    "        \n",
    "    # Create the camera pose matrix\n",
    "    R = rot\n",
    "    Rt = np.block([R.T, -R.T @ tvec.reshape(3, 1)])\n",
    "    Rt = np.vstack([Rt, [0, 0, 0, 1]])\n",
    "\n",
    "    ax = pt.plot_transform(A2B=Rt, s=2)\n",
    "\n",
    "    # Plot the camera\n",
    "    pc.plot_camera(ax, cam2world=Rt, M=lam, sensor_size=sensor_size, virtual_image_distance=0.8)\n",
    "\n",
    "    # Set limits and view angle\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.set_zlim(-30, 30)\n",
    "    ax.view_init(30, 70)\n",
    "    plt.grid()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    image = fig2img(fig)\n",
    "    \n",
    "    return image\n",
    "    \n",
    "\n",
    "@staticmethod\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)  # Load the JSON data\n",
    "\n",
    "    # Convert the specific keys to NumPy arrays\n",
    "    lam = np.array(data['lambda'])  # Convert the 'mtx' list to a NumPy array\n",
    "    dist = np.array(data['distortion'])  # Convert the 'dist' list to a NumPy array\n",
    "\n",
    "    return lam, dist  # Return both arrays\n",
    "\n",
    "\n",
    "def fig2img(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img\n",
    "\n",
    "    \n",
    "class Clicks:\n",
    "    @staticmethod\n",
    "    def capture(points_list):\n",
    "        return np.array(points_list, dtype=np.float32) if points_list else np.array([]).reshape(0, 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_numbered(image, points, radius=8):\n",
    "        if isinstance(image, np.ndarray): image = Image.fromarray(image)\n",
    "        img = image.copy()\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        try: font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "        except: font = ImageFont.load_default()\n",
    "        for i, (x, y) in enumerate(points):\n",
    "            draw.ellipse([x-radius, y-radius, x+radius, y+radius], outline=(255, 0, 0), width=2, fill=(255, 255, 255))\n",
    "            draw.text((x-5, y-8), str(i+1), fill=(0, 0, 0), font=font)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d230bd77-f91a-4cec-897a-9e5d7a99a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pose_estimation_demo():\n",
    "    # State\n",
    "    state = {'points': [], 'image': None}\n",
    "    \n",
    "    def on_click(evt: gr.SelectData, img):\n",
    "        if img is None: \n",
    "            return img, \"No image\", \"\"\n",
    "    \n",
    "        x, y = evt.index\n",
    "        state['points'].append([int(x), int(y)])\n",
    "    \n",
    "        # Set the original image if it's not already set\n",
    "        if state['image'] is None:\n",
    "            state['image'] = img.copy()  # Store a copy of the original image\n",
    "    \n",
    "        # Draw points on the original image\n",
    "        updated = Clicks.draw_numbered(state['image'], state['points'])  \n",
    "        return np.array(updated), f\"Selected {len(state['points'])} points\", json.dumps(state['points'])\n",
    "\n",
    "    def undo_last(img):\n",
    "        if state['points']: \n",
    "            state['points'].pop()  # Remove the last point\n",
    "        if img is not None:\n",
    "            updated = Clicks.draw_numbered(state['image'], state['points'])  # Redraw the image with the updated points\n",
    "            return np.array(updated), f\"Selected {len(state['points'])} points\", json.dumps(state['points'])\n",
    "        return img, \"No points selected\", \"[]\"\n",
    "\n",
    "    def clear_points(img):\n",
    "        state['points'].clear()  # Clear all points\n",
    "        if img is not None:\n",
    "            updated = Clicks.draw_numbered(state['image'], [])  # Redraw the image with no points\n",
    "            return np.array(updated), \"Cleared\", \"[]\"\n",
    "        return img, \"No points selected\", \"[]\"\n",
    "\n",
    "    def estimate_poses():\n",
    "        img = state['image']\n",
    "        \n",
    "        REF_POINTS = np.array([[0, 0, 0], [5, 0, 0], [5, 8, 0], [0, 8, 0]], dtype=np.float32).T\n",
    "        img_points = np.array(state['points'], dtype=np.float32)\n",
    "\n",
    "        lam, dist = read_json('calibration.json')\n",
    "\n",
    "        rh, th = get_pose_hom(lam, dist, img_points, REF_POINTS)\n",
    "        rc, tc = get_pose_cv(lam, dist, img_points, REF_POINTS)\n",
    "\n",
    "        axes = img_with_axis(img, lam, rc, tc, dist)\n",
    "\n",
    "        pose = get_camera_pose_plot(lam, img, rc, tc)\n",
    "\n",
    "        tc = tc.T\n",
    "        homo_str = \"R: \" + np.array_str(rh) + \"\\n\\nT: \" + np.array_str(th)\n",
    "        cv_str = \"R: \" + np.array_str(rc) + \"\\n\\nT: \" + np.array_str(tc)\n",
    "\n",
    "        #print(rh)\n",
    "        #print(rc)\n",
    "        return homo_str, cv_str, axes, pose\n",
    "    \n",
    "    with gr.Blocks(title=\"Pose Estimation Demo\") as demo:\n",
    "        gr.Markdown(\"# Pose Estimation from 2D-3D Correspondences\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                img = gr.Image(label=\"Upload Image (click to add points)\", type=\"numpy\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    undo_btn = gr.Button(\"Undo\", size=\"sm\")\n",
    "                    clear_btn = gr.Button(\"Clear\", size=\"sm\")\n",
    "                status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                points_json = gr.Textbox(label=\"Selected Points\",value=\"[]\", interactive=False)\n",
    "        \n",
    "        with gr.Row():\n",
    "            estimate_btn = gr.Button(\"Process Points\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                homo_result = gr.Textbox(label=\"Homography to Pose\", lines=6, interactive=False)\n",
    "                cv_result = gr.Textbox(label=\"OpenCV solvePnP\", lines=6, interactive=False)\n",
    "            with gr.Column():\n",
    "                axes_img = gr.Image(label=\"Coordinate Axes Overlay\", interactive=False)\n",
    "                plot_3d = gr.Image(label=\"3D Camera Pose\", interactive=False)          \n",
    "        \n",
    "        # Event handlers\n",
    "        img.select(on_click, inputs=[img], outputs=[img, status, points_json])\n",
    "        undo_btn.click(lambda img: undo_last(img), inputs=[img], outputs=[img, status, points_json])\n",
    "        clear_btn.click(lambda img: clear_points(img), inputs=[img], outputs=[img, status, points_json])\n",
    "        estimate_btn.click(estimate_poses, outputs=[homo_result, cv_result, axes_img, plot_3d])\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "19da02f9-6029-4abc-b20b-2661f7507460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7930\n",
      "* Running on public URL: https://85203c927f3d62752b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://85203c927f3d62752b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the demo\n",
    "demo = create_pose_estimation_demo()\n",
    "demo.launch(debug=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3817cc-6970-46ab-b49b-7975c39fcc83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
